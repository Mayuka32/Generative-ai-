{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayuka32/Generative-ai-/blob/main/Spam\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# Ensure NLTK stopwords are downloaded\n",
        "try:\n",
        "    stopwords.words('english')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Cleans and preprocesses text by lowercasing, removing non-alphabetic chars,\n",
        "    and removing stopwords.\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text) # Remove non-alphabetic characters, keep spaces\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stopwords.words('english')]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# --- 1. Define the Dataset Directly in Code ---\n",
        "# This is our small, predefined dataset for demonstration\n",
        "data = {\n",
        "    'label': [\n",
        "        'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham',\n",
        "        'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham'\n",
        "    ],\n",
        "    'message': [\n",
        "        \"Hey, how are you doing today?\",\n",
        "        \"WINNER! You've won a Â£1000 cash prize! Text CLAIM to 800-888 to claim. T&Cs apply.\",\n",
        "        \"Just got home, cooking dinner now.\",\n",
        "        \"URGENT! Your account has been suspended. Click this link to reactivate now: http://malicious.link\",\n",
        "        \"Can we meet up tomorrow?\",\n",
        "        \"Don't forget to buy milk.\",\n",
        "        \"Free entry to our exclusive competition for a chance to win a new car. Reply YES to 87878.\",\n",
        "        \"Sounds good! See you then.\",\n",
        "        \"Congratulations! You've been selected for a free holiday to Hawaii. Call 09061701549.\",\n",
        "        \"I'm at the library, studying.\",\n",
        "        \"Did you get my last text?\",\n",
        "        \"Cash a prize from our company! Send your bank details for transfer now! Click: http://fakelinks.com\",\n",
        "        \"Okay, no problem.\",\n",
        "        \"What time is the movie?\",\n",
        "        \"Running a bit late, be there in 10.\",\n",
        "        \"Limited time offer! Get 50% off all products. Visit our store at www.scamshop.net.\",\n",
        "        \"Happy birthday!\",\n",
        "        \"Let's grab coffee soon.\",\n",
        "        \"You have 1 new voicemail. Call +123456789 to retrieve. Cost Â£1.50/min.\",\n",
        "        \"Finished work early today.\"\n",
        "    ]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"--- Starting Model Training and Saving Process with In-Code Data ---\")\n",
        "\n",
        "# Preprocess messages and convert labels\n",
        "df['message'] = df['message'].apply(preprocess_text)\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Split data for training and testing\n",
        "X = df['message']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize text using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "# X_test_vectorized = vectorizer.transform(X_test) # Not strictly needed for this app if only saving model\n",
        "\n",
        "# Train a Multinomial Naive Bayes Classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Evaluate the model (optional, for verification)\n",
        "# y_pred = model.predict(X_test_vectorized)\n",
        "# print(f\"Model accuracy on test set: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "\n",
        "# Save the trained model and vectorizer to .pkl files\n",
        "# These files will be loaded by the Gradio app\n",
        "with open('spam_model_in_code.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "with open('tfidf_vectorizer_in_code.pkl', 'wb') as f:\n",
        "    pickle.dump(vectorizer, f)\n",
        "\n",
        "print(\"Model (spam_model_in_code.pkl) and Vectorizer (tfidf_vectorizer_in_code.pkl) saved successfully!\")\n",
        "print(\"These files are now ready for the Gradio app.\")\n",
        "\n",
        "# --- 2. Load Predefined Model and Vectorizer (for the Gradio App) ---\n",
        "# This part executes when the script is run and serves the Gradio app\n",
        "\n",
        "try:\n",
        "    with open('spam_model_in_code.pkl', 'rb') as f:\n",
        "        loaded_model = pickle.load(f)\n",
        "    with open('tfidf_vectorizer_in_code.pkl', 'rb') as f:\n",
        "        loaded_vectorizer = pickle.load(f)\n",
        "    print(\"Predefined model and vectorizer loaded successfully for inference!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Model or vectorizer files not found.\")\n",
        "    print(\"Ensure the training section above ran successfully and created 'spam_model_in_code.pkl' and 'tfidf_vectorizer_in_code.pkl'.\")\n",
        "    exit()\n",
        "\n",
        "def predict_spam(message):\n",
        "    \"\"\"\n",
        "    Predicts whether a message is spam or not using the loaded model.\n",
        "    \"\"\"\n",
        "    if not message:\n",
        "        return \"Please enter a message to analyze.\"\n",
        "\n",
        "    preprocessed_message = preprocess_text(message)\n",
        "    # Transform the single message using the loaded vectorizer\n",
        "    vectorized_message = loaded_vectorizer.transform([preprocessed_message])\n",
        "    prediction = loaded_model.predict(vectorized_message)[0]\n",
        "\n",
        "    if prediction == 1:\n",
        "        return \"SPAM! ðŸš¨\"\n",
        "    else:\n",
        "        return \"Not Spam (HAM) âœ…\"\n",
        "\n",
        "# Create the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_spam,\n",
        "    inputs=gr.Textbox(lines=5, label=\"Enter Message Here\", placeholder=\"Type a message to check if it's spam...\"),\n",
        "    outputs=gr.Label(label=\"Prediction\"),\n",
        "    title=\"SMS Spam Detector (In-Code Data)\",\n",
        "    description=\"This app uses a machine learning model trained on a small dataset embedded directly in the code.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "# Use share=True if running in Google Colab to get a public URL.\n",
        "# For local execution, you can use share=False or omit it.\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n--- Launching Gradio App ---\")\n",
        "    iface.launch(share=True)"
      ],
      "metadata": {
        "id": "KqQwSIcgFPKD",
        "outputId": "ad1d6702-1994-4b5f-d13d-2960dc1265c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Model Training and Saving Process with In-Code Data ---\n",
            "Model (spam_model_in_code.pkl) and Vectorizer (tfidf_vectorizer_in_code.pkl) saved successfully!\n",
            "These files are now ready for the Gradio app.\n",
            "Predefined model and vectorizer loaded successfully for inference!\n",
            "\n",
            "--- Launching Gradio App ---\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a2ed9b81023a5a0c4d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a2ed9b81023a5a0c4d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}